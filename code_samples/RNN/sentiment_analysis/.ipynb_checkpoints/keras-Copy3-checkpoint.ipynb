{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Estimators\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "# Model builder\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "\n",
    "print (tf.__version__) # tested with v1.1\n",
    "\n",
    "# Input function\n",
    "from tensorflow.python.estimator.inputs import numpy_io\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# Enable TensorFlow logs\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# keras\n",
    "from tensorflow.contrib.keras.python.keras.preprocessing import sequence\n",
    "from tensorflow.contrib.keras.python.keras.layers import Embedding, GRU, Dense, SimpleRNN\n",
    "from tensorflow.contrib.keras.python.keras.layers import Reshape, Activation\n",
    "\n",
    "# data\n",
    "from tensorflow.contrib.keras.python.keras.datasets import imdb \n",
    "\n",
    "\n",
    "# Run an experiment\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 88584 words in the files\n"
     ]
    }
   ],
   "source": [
    "# map word to index\n",
    "word_to_index = imdb.get_word_index()\n",
    "# map index to word\n",
    "index_to_word = {}\n",
    "num_words = 0\n",
    "for k in word_to_index: \n",
    "    index_to_word[word_to_index[k]] = k\n",
    "    num_words += 1\n",
    "\n",
    "# turn a sequence into a sentence\n",
    "def get_sentence(seq):\n",
    "    sentence = ''\n",
    "    for v in seq:\n",
    "        if v != 0: # 0 means it was just added to the sentence so it could have maxlen words\n",
    "            sentence += index_to_word[int(v)] + ' '\n",
    "    return sentence\n",
    "\n",
    "# turn a sentence into a sequence\n",
    "def gen_sequence(sentence):\n",
    "    seq = []\n",
    "    for word in sentence:\n",
    "        seq.append(word_to_index[word])\n",
    "    return np.asarray(seq, dtype=np.float32)\n",
    "\n",
    "print('there are', num_words, 'words in the files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Example of a negative review\n",
      "------------------------------\n",
      "Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n",
      "\n",
      "------------------------------\n",
      "Example of a positive review\n",
      "------------------------------\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n"
     ]
    }
   ],
   "source": [
    "# ------------------- negative\n",
    "print('-' * 30)\n",
    "print('Example of a negative review')\n",
    "print('-' * 30)\n",
    "\n",
    "x = open('data/train/neg/0_3.txt')\n",
    "r = x.readline()\n",
    "print(r)\n",
    "\n",
    "# ------------------ positive\n",
    "print()\n",
    "print('-' * 30)\n",
    "print('Example of a positive review')\n",
    "print('-' * 30)\n",
    "\n",
    "x = open('data/train/pos/0_9.txt')\n",
    "r = x.readline()\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
    "\n",
    "# lets make things faster\n",
    "limit = 3200\n",
    "maxlen = 200\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "x_train = x_train[:limit].astype('float32')\n",
    "y_train = y_train[:limit].astype('int32')\n",
    "\n",
    "x_test = x_test[:limit].astype('float32')\n",
    "y_test = y_test[:limit].astype('int32')\n",
    "\n",
    "# y to onehot\n",
    "y_train_one_hot = np.zeros((limit, 2), dtype=np.float32)\n",
    "for i in range(limit):\n",
    "    y_train_one_hot[i][y_train[i]] = 1\n",
    "\n",
    "y_test_one_hot = np.zeros((limit, 2), dtype=np.float32)\n",
    "for i in range(limit):\n",
    "    y_test_one_hot[i][y_test[i]] = 1\n",
    "\n",
    "#print(y_train)\n",
    "#print(y_train_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 32\n",
    "STEPS = 1000\n",
    "\n",
    "# Define the model, using Keras\n",
    "def model_fn(features, targets, mode, params):\n",
    "\n",
    "    embed = Embedding(num_words, 128)(features['x'])\n",
    "    gru = GRU(128)(embed)\n",
    "    logits = Dense(2)(gru)\n",
    "    logits_softmax = Activation('softmax')(logits)\n",
    "\n",
    "    # make logits shape the same as the targets: (BATCH_SIZE, 2)\n",
    "    if mode != learn.ModeKeys.PREDICT:\n",
    "        logits = tf.reshape(logits, shape=[BATCH_SIZE, 2])\n",
    "        logits_softmax = tf.reshape(logits, shape=[BATCH_SIZE, 2])\n",
    "        targets = tf.reshape(targets, shape=[BATCH_SIZE, 2])\n",
    "    \n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "            onehot_labels=targets, logits=logits)\n",
    "    \n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            optimizer=\"Adam\")\n",
    "    \n",
    "    predictions = {\n",
    "        \"probabilities\": tf.nn.softmax(logits)\n",
    "    }\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "                    tf.argmax(input=logits_softmax, axis=1),\n",
    "                    tf.argmax(input=targets, axis=1))\n",
    "    }\n",
    "\n",
    "    return model_fn_lib.ModelFnOps(\n",
    "        mode=mode,\n",
    "        predictions=predictions,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_task_type': None, '_evaluation_master': '', '_save_checkpoints_secs': 600, '_environment': 'local', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc9de78ce10>, '_is_chief': True, '_model_dir': None, '_master': '', '_tf_random_seed': None, '_save_checkpoints_steps': None}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmptz_itspc\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmptz_itspc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.693547, step = 1\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-01-18:57:46\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptz_itspc/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-01-18:57:52\n",
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.503438, global_step = 1, loss = 0.69712\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "INFO:tensorflow:Validation (step 1): accuracy = 0.503438, loss = 0.69712, global_step = 1\n",
      "INFO:tensorflow:global_step/sec: 3.55113\n",
      "INFO:tensorflow:loss = 0.506815, step = 101 (28.161 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /tmp/tmptz_itspc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.292846.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-01-18:58:34\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptz_itspc/model.ckpt-200\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-01-18:58:40\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.726562, global_step = 200, loss = 0.605021\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.7265625, 'global_step': 200, 'loss': 0.60502124}, [])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[ ]:\n",
    "\n",
    "# Input functions\n",
    "\n",
    "# this couldn't possibly be right... \n",
    "x_train_dict = {'x': x_train }\n",
    "\n",
    "train_input_fn = numpy_io.numpy_input_fn(\n",
    "          x_train_dict, y_train_one_hot, batch_size=BATCH_SIZE, \n",
    "           shuffle=False, num_epochs=2, \n",
    "            queue_capacity=1000, num_threads=1)\n",
    "\n",
    "x_test_dict = {'x': x_test }\n",
    "\t\n",
    "test_input_fn = numpy_io.numpy_input_fn(\n",
    "          x_test_dict, y_test_one_hot, batch_size=BATCH_SIZE, shuffle=False, num_epochs=1)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "model_params = {\"learning_rate\": LEARNING_RATE}\n",
    "\n",
    "# create estimator\n",
    "estimator = tf.contrib.learn.Estimator(model_fn=model_fn, params=model_params)\n",
    "\n",
    "# create experiment\n",
    "def generate_experiment_fn():\n",
    "  \n",
    "  \"\"\"\n",
    "  Create an experiment function given hyperparameters.\n",
    "  Returns:\n",
    "    A function (output_dir) -> Experiment where output_dir is a string\n",
    "    representing the location of summaries, checkpoints, and exports.\n",
    "    this function is used by learn_runner to create an Experiment which\n",
    "    executes model code provided in the form of an Estimator and\n",
    "    input functions.\n",
    "    All listed arguments in the outer function are used to create an\n",
    "    Estimator, and input functions (training, evaluation, serving).\n",
    "    Unlisted args are passed through to Experiment.\n",
    "  \"\"\"\n",
    "\n",
    "  def _experiment_fn(output_dir):\n",
    "\n",
    "    train_input = train_input_fn\n",
    "    test_input = test_input_fn\n",
    "    \n",
    "    return tf.contrib.learn.Experiment(\n",
    "        estimator,\n",
    "        train_input_fn=train_input,\n",
    "        eval_input_fn=test_input\n",
    "    )\n",
    "  return _experiment_fn\n",
    "\n",
    "# run experiment \n",
    "learn_runner.run(generate_experiment_fn(), '/tmp/outputdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "preds = list(estimator.predict(input_fn=test_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 3022\n",
      "------------------------------\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     1    31     7     4   249   108    13    28   126\n",
      "   110    21   576   163    24    23  1288   151   175   136    15  1367\n",
      "   233     8    81    19  8506   883   229    42   116     9   913  4621\n",
      "    56    10    10    13   386    14    22    18    32  7446  9315    38\n",
      "    78    15    25   144  5566    83  2129    33    49   213    11     4\n",
      "    22    82    67  4550 12556     4 23454    18     4   172   282    10\n",
      "    10   259   334   798    14    22    40     4  3196   549    18   451\n",
      "     7   503   102     7   265    10    10   358]\n",
      "prediction: 0\n",
      "target: 0\n",
      "sentence: the by br of sure many was one your life not told makes his are thinks old us scenes for places last in people film identified reading guy it's love it weird gangsters she i i was wonderful as you but an october hispanic her do for have real daughter's first delivered they good come this of you other can september endurance of state's but of every everything i i especially fan typical as you just of kurt type but beginning br child characters br screen i i use \n",
      "\n",
      "test: 2210\n",
      "------------------------------\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     1    13    92   124    51    49    84    71   536    54    36   301\n",
      "    14    20    16    78    12    16    87   356  1478  4551   422    12\n",
      "    16   364   352     5     4   318   962  1177    14    21    15     9\n",
      "    24    51    25    67     6  1478    20    18    25   106    12    18\n",
      "  1478    82  2901    16   321    13   258    14    20   642     5   441\n",
      "    13   131  4080    56    54    13  2283  1478    23    15  4998 44554\n",
      "   150    13    80   974    14    20     9    24    18   316    48    25\n",
      "    92    40   503   102    25   242   528    40    14    31    48    25\n",
      " 17990   194   352   302     5   156  7010   788    21    48    25    40\n",
      "  3688  1231     5   125     4  1513   920   924  1847    14    20     9\n",
      "    18    25    10    10 11340     4   711   896]\n",
      "prediction: 0\n",
      "target: 1\n",
      "sentence: the was then does when good great than girls no from takes as on with do that with him need hasn't inferior title that with along wrong to of excellent personal producers as not for it his when have can is hasn't on but have character that but hasn't other regard with shot was although as on started to overall was these occasion she no was winner hasn't are for spain thriller's years was into appear as on it his but seeing what have then just child characters have away parts just as by what have olympics thought wrong instead to before dumped elements not what have just subsequent values to better of jerry realize writers players as on it but have i i 1928 of easily imdb \n",
      "\n",
      "test: 2456\n",
      "------------------------------\n",
      "[   49    84   203   135    15   241 16024  2957    99   522     8    15\n",
      "  1614  2425   190    13    81    24   104    40    15    88    15 13131\n",
      " 16032     4    20     8    97     6    53  1614  4762  4085    23     4\n",
      "   904    19    53 46459     5  1663   305     7     4   578  2097     7\n",
      "  5614     5  8511    63 25861    85   102    19   729   537    10    10\n",
      "    23     4   105    39   241 16024    75    70   169  1807    39     4\n",
      "  3955   438    39   167     5  2979   308  5701  1677  3579   102     8\n",
      "     4  1629   189   108     4   307  2549     4  4116  5155     4 14654\n",
      "   525    12    62    28    77    55   776     8    97    98   413    11\n",
      "  4086  5249  4786    34    68  5239    11     4   881    21    12     9\n",
      "   142  5481    15     4   881 10022     4  2118     8    97    98   147\n",
      "    84    19  3084   712    63    11    53    42   329  2461   101   415\n",
      "    70   169    23    27    41  1320     8  8690    10    10   241 16024\n",
      "     9    35   321    20   625    64  1854     9    15     4   277   764\n",
      "     6   227  3889    21    63 20999    15    19     6   176     7  1123\n",
      "   791    12    80    30    55   221     8    67   375  3451   237    29\n",
      "    47    69     6    87  2016    19    14    20]\n",
      "prediction: 0\n",
      "target: 1\n",
      "sentence: good great action why for am venturing risk movies etc in for therefore promising take was people his two just for most for clinical infernal of on in could is up therefore nuts aid are of directors film up patricide to sleep john br of living jennifer br insipid to bliss really barbet because characters film sets obviously i i are of films or am venturing bad well same dressed or of conversations entertaining or going to attacked audience rhythm desperate returning characters in of listen fact many of version occasional of official subjected of bearded won't that story one will time actual in could any lost this cary ross legal who were filling this of dr not that it back lip for of dr researched of leader in could any now great film spin words really this up it's read plans think piece well same are be about mistake in emmy i i am venturing it so shot on david see knowledge it for of once red is far recognized not really timone for film is quite br biggest follow that into at time done in can couple korean he's all there me is him sea film as on \n",
      "\n",
      "test: 2508\n",
      "------------------------------\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     1  1294   558    18 17279     5     4   312  2125     7\n",
      "    45   702   930    60    19    15    13   426   870   143   101    53\n",
      "     7    15  4995    54    36   385   638     4   154  1395  2254    18\n",
      " 11095    13   520    56     5 15243    12     9    14     4   118    15\n",
      "  6196  1308    70   216    56    19    18  2324  3527    89    44    49\n",
      "   154  2239   305     4   326     7     6 24199   318  1929  4814    16\n",
      "    78   195    12   186    40    36   473     8   607   278    34   260\n",
      "   285   814    46    11     4  1411    51    53    70    13   135    12\n",
      "    16    38   373    15    13    92   104    13    70   216    56    19\n",
      "   195   411     8  7397    18   834     8   733    12    21    12   272\n",
      "    40    31    53   347    80    81    12   607   129    58   387   584\n",
      "   129   278    23    14   912     7     6    22]\n",
      "prediction: 0\n",
      "target: 0\n",
      "sentence: the unbelievable moment but somebody's to of during awards br if future deep which film for was against expected i'm think up br for pink no from moments light of work expectations choose but shuttle was eyes she to curator that it as of where for joker journey well saw she film but substance ego don't has good work produce john of less br is maidens excellent kinda attorney with do that's that horror just from children in looked sense who our dvd means some this of bother when up well was why that with her tell for was then two was well saw she film that's dialogue in mins but dance in mystery that not that different just by up top into people that looked man my episode including man sense are as male br is you \n",
      "\n",
      "test: 687\n",
      "------------------------------\n",
      "[ 1674    11    61   523  7339  8925     6   389   284    61   205   559\n",
      "  1131   639    12  1932  1578    72     7   111  3080    13    28  2051\n",
      "    11    61   113    38    13   901    14    17     6  6493     8   185\n",
      "     5   154    57    31     9 12224     8   845     9    11  1130    18\n",
      "   178    10    10    13   784     8   135    15   341     9   170     8\n",
      "   593    21    14    65    16     4    86    58    13   219   341    17\n",
      "    24     6    78   155    21     6   173     7   113    16   179  1227\n",
      "    11    14    65    13   191   339    12    12    16     6   113  2546\n",
      "   561    18    72     5    80 40691    30    10    10     5    18    15\n",
      "    10    10    13   119    25  1240 15126     5    13   131   377    76\n",
      "     7   129   157    11   113    56   366     4   251    25  1131     5\n",
      "   129 14375  5582   123     5  1294    25  1620 15126    18  1895     4\n",
      " 23100  1239  1202    13    81  1294    25    32     7   129  1001  3010\n",
      " 11816     5 30276    10    10     4   868     9    43     6   868     5\n",
      "     6   123     9    43     6   123    21  1546    80   987  1236    15\n",
      "  1437     4   182    80   124    10    10  1294    25    10    10     5\n",
      "    18    32    37   824    72   837  1236   837]\n",
      "prediction: 0\n",
      "target: 1\n",
      "sentence: rip this only directed gigantic percent is small shows only right took effective hilarious that cage inspired we br plot overcome was one window this only acting her was situation as movie is immortal in got to work even by it hardship in lee it this consider but want i i was tale in why for home it part in ago not as their with of how my was least home movie his is do 10 not is lot br acting with world steve this as their was big 3 that that with is acting princess writer but we to into likeability at i i to but for i i was did have yeah feud to was these start get br man another this acting she friends of hard have effective to man gigi overlong ever to unbelievable have ready feud but japan of that'd grade shooting was people unbelievable have an br man inside ashamed anatomy to presson i i of who's it out is who's to is ever it out is ever not flying into pay alive for victim of young into does i i unbelievable have i i to but an like tom we third alive third \n",
      "\n",
      "test: 3171\n",
      "------------------------------\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     1     4  1603  1315     9     6  2723\n",
      "   212   368     7   105  1075    11 18899     7     6   147    65    63\n",
      "   716     6   185 26897  1475  7455    37   304     6   292  8248    35\n",
      "  1603  1315     5   461 18916    11     6   588   736  7023    48    25\n",
      "    70   683    12    15    14   364  6827   106  1367    57   836    57\n",
      "  3487    57   453    57   206  3669   171   163   388     6  8419     7\n",
      "  1006     5   220    57   883     4  1603  1315     9  5084  2441  2582\n",
      "  1644    18    64     4    91 14949  5721 17924]\n",
      "prediction: 0\n",
      "target: 0\n",
      "sentence: the of nasty wow it is fabulous must truly br films convincing this lizards br is now their really local is got primed bruce brent like beautiful is together frat so nasty wow to friend prosthetics this is please appears followers what have well single that for as along mythology character places even brought even homage even lives even without documentaries again makes understand is mercifully br twist to family even reading of nasty wow it confess display forest martial but see of its inimitable representation teenaged \n",
      "\n",
      "test: 2408\n",
      "------------------------------\n",
      "[12614    34     4  4927  9338    17    73    17   112 12868    34     4\n",
      " 10154     7     4   719 10888  1333  4467     7    41  2813  5150     8\n",
      "  1183    11     9  7415    33   112    88     7    27  2920  5014    15\n",
      "  1212    12   203    82    28     8    81    19    90   112     6 28061\n",
      "  6746    21   141    26  5965  1212   151    13  2230  2913   196   159\n",
      "    36    71  6272    33     4   130     7     4   251 19039    16   269\n",
      "     8    79  1404    11   113   717  1126   439     9   397     4 65561\n",
      "    33     4   719  8894  1333     8    40    41  3285  5288   336    38\n",
      "    15    59    70    79     6  1304    19     4 24112 31360   428   554\n",
      "    42    38    13  8676    10    10   553    11 17441    94   862   398\n",
      "   913  3757    19   835   270  1328     5  7055     6   176     7   676\n",
      "   849  3600    48    25    71   502     8   870   143    12     8    45\n",
      "  1174    12    66     9     6 26683    50     9    15   888   951   151\n",
      "     7   138   122    38   111     7     4   204   156    24   994    17\n",
      "  3630     8   112  2959    34  3185    37    23  2300    33   222   610\n",
      "    68  9538   279    36    43  1173  1803    42   382    13  1781    36\n",
      "   165   332     4   229  1231     8     4   204]\n",
      "prediction: 0\n",
      "target: 0\n",
      "sentence: erica who of performs brits movie much movie never hiking who of infectious br of entertainment democratic blue pretending br about cabin tube in situations this it rice they never most br be amongst whoopi for cult that action other one in people film made never is subverting arranged not should he dylan cult old was fill bat both new from than confront they of here br of hard ferocious with looks in also stands this acting sequence runs she's it often of hoi they of entertainment expresses blue in just about gag teaches help her for would well also is terrific film of unfit hallam's picture heard it's her was diaz i i killed this panther make zombie keep weird providing film imagine place g to israeli is quite br turned de achievement what have than turns in expected i'm that in if showed that had it is dark' more it for 20 cheesy old br such off her plot br of i've before his fighting movie shortly in never sold who suggests like are strongly they there's song were snippets reason from out win johnny it's came was twenty from look you're of guy values in of i've \n",
      "\n",
      "test: 2095\n",
      "------------------------------\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     1  1604  3214   558    13  3117   260     8   106    14    22\n",
      "   689   211    11    61  2481   313     5    16    12  2150     6    65\n",
      "     7   383     5  1865     5    55   706  5639   116   894    25    26\n",
      "    33 13774   112   579     8   106    14   798    12 32350  2673    43\n",
      "  2085    29   566   511 26339 32805    82   520     4    91  2150   116\n",
      "   126    11   101     7    27   108    50    16    24    31   173     7\n",
      "    14    22    93    72   462    42    97    72  1783    42   235   101\n",
      "  1426    13    62    30   770    84   165   510    14    13    28   306\n",
      "    49  2150   108    11    61   113    21    14    62    30    11    61\n",
      "   677   249   108   126     4   228    11    12   286    52     5     4\n",
      "   769    13   104    16    93    56    34     6   378     7   493    37\n",
      "  5175     6  7757     5    43  1829   180  1040   747  3985   757     5\n",
      "    95    93    12    83     6    22   427  2150]\n",
      "prediction: 0\n",
      "target: 0\n",
      "sentence: the arthur assistant moment was technique our in character as you attention gets this only latest everyone to with that commercial is their br recommend to kate to time 8 firing love superb have he they cylon never coming in character as typical that florida's alice out ages all hit favorite lives' vests other eyes of its commercial love your this think br be many more with his by lot br as you way we dark it's could we wanting it's might think fascinating was story at named great look town as was one himself good commercial many this only acting not as story at this only strange sure many your of making this that three very to of using was two with way she who is stars br behind like griffith is lo to out superman things cold theater kidding mention to them way that first is you boy commercial \n",
      "\n",
      "test: 1266\n",
      "------------------------------\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     1   689   183  3704    72    17     8    14    22\n",
      "  4633    12   381 38280 10303     7  1063  2246    37     9   210     6\n",
      "  1742     8   106    12   944   530   162  9109   524  5182 12751    12\n",
      "     9   814    11  9058    19     4   162  9109    22 17150 65044     6\n",
      "   464  1178    12     8    72   190    13    16  1254   685     4   226\n",
      "   769     9  1755     5  2732    19    55   117  3473   116     9   478\n",
      "    21  5182     9   472   467   343     4    85   156     5  1507    26\n",
      "    32   864    21    13   244  7745    19    98    32  1212    39     4\n",
      "   327 26406    63    26 20674   469     4    20     5 10303     5  5182\n",
      "    14    22   218    55    52    38     4  1515     7     4    65     9\n",
      "    92   106    12   894    25    66   181     8]\n",
      "prediction: 0\n",
      "target: 0\n",
      "sentence: the attention seems 50's we movie in as you greedy that mean illuminator sybil br members sheriff like it point is x in character that mess themselves actually archer horrible masks idyllic that it means this pond film of actually archer you lynchian gourmet is under culture that in we take was with fair due of script using it grand to summary film time over canada love it sound not masks it Â– 4 short of because before to system he an believable not was rather crooks film any an cult or of mind enhancements really he winch unfortunately of on to sybil to masks as you interesting time very her of creative br of their it then character that superb have had pretty in \n",
      "\n",
      "test: 1405\n",
      "------------------------------\n",
      "[ 1041    14  1253     7 43370     4     9    55    52   849   210    31\n",
      "     7    61  1640 12344   537    13    16  3786    15    12   238    30\n",
      "    44 58115    73    12    16     6   117   227    21    64     6   117\n",
      "   227     5     4   130     4   959    16  1562   441   628 22887  1999\n",
      "     8    30    73 15731 19492    17 12344     5    17   409    28  3381\n",
      "    46     4    85   323     7    14   123     9  8268 33269    37  1348\n",
      "   100    24    30 26808    17   717 24671    13    82    66   510 11739\n",
      "    37    16  1466    23    17     4  2410 84728 11679    21    66     4\n",
      "   973    16   179  9197   469    10    10    31   213     9  5290   125\n",
      "    18     4    24   112   502     8  4974 82015    99   111  9400    83\n",
      "     4   477  3496   234     4   970    19     4    80     5   313  7945\n",
      "    16    32     6   227  1744   261    13   161   330    89    36 19518\n",
      "    56     4  2438     7     4   223    11     4   274     4   223  2840\n",
      "     9    66   179  2732     4   477   388    54     4  2748     9  2029\n",
      "   190    26    66   966    73   224     5    13   258     4    55   130\n",
      "    54    36    32   563   179  1301    14     9    66    31     7     4\n",
      "    55   118     7     4 12344   201    38   230]\n",
      "prediction: 0\n",
      "target: 1\n",
      "sentence: plain as ability br postpone of it time very de point by br only asks persistent obviously was with craig for that 2 at has necking much that with is over far not see is over far to of here of effect with ground overall english deneuve we've in at much borne pitying movie persistent to movie live one tea some of because idea br as ever it cohesive fruity like justice after his at debauchery movie sequence stabbings was other had town veronika like with henry are movie of witness padarouski simulated not had of powerful with world sailors unfortunately i i by come it loneliness better but of his never turns in expressed unidimensional movies plot downtown first of amazing brilliance since of casting film of into to everyone outrageously with an is far returns believe was nothing second don't from zion she of forgettable br of whole this of ending of whole children's it had world summary of amazing understand no of lisa it remembered take he had monster much bit to was although of time here no from an cannot world date as it had by br of time where br of persistent original her anything \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of outputs we want to see the prediction\n",
    "NUM_EVAL = 10\n",
    "def check_prediction(x, y, p, index):\n",
    "    print('prediction:', np.argmax(p[index]))\n",
    "    print('target:', np.argmax(y[index]))\n",
    "    print('sentence:', get_sentence(x[index]))\n",
    "\n",
    "for i in range(NUM_EVAL):\n",
    "    index = np.random.randint(limit)\n",
    "    print('test:', index)\n",
    "    print('-' * 30)\n",
    "    print(np.asarray(x_test[index], dtype=np.int32))\n",
    "    check_prediction(x_test, y_test_one_hot, preds, index)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
